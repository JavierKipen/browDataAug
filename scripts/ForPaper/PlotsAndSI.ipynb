{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cef8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import copy\n",
    "from scipy import stats\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdad4aa",
   "metadata": {},
   "source": [
    "# Main paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284c75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b72d0460",
   "metadata": {},
   "source": [
    "# Supporting Information\n",
    "\n",
    "## Showing accuracy improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f464b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies_LR_match_str(str_to_match,lr_folder):\n",
    "    N=0;\n",
    "    all_accs=np.array([])\n",
    "    for dirpath, dnames, fnames in os.walk(lr_folder):\n",
    "        for f in fnames:\n",
    "            if f.endswith(\".csv\") and (str_to_match in f):\n",
    "                df=pd.read_csv(lr_folder+\"/\"+f)\n",
    "                curr_accs=df.iloc[0:3,0].to_numpy()\n",
    "                if all_accs.size==0:\n",
    "                    all_accs=copy.deepcopy(curr_accs)\n",
    "                else :\n",
    "                    all_accs=np.vstack([all_accs, curr_accs])\n",
    "                N=N+1;\n",
    "    return all_accs\n",
    "\n",
    "def get_accs_to_compare():\n",
    "    all_accs_Brow=get_accuracies_LR_match_str(\"WBrowAug_090_N1_2048_N2_1024\",\"../../results/CompareLRs/5E-04\")\n",
    "    all_accs_noBrow=get_accuracies_LR_match_str(\"Reproduction_N1_2048_N2_1024\",\"../../results/CompareLRs/5E-04\")\n",
    "    return all_accs_noBrow,all_accs_Brow;\n",
    "\n",
    "def check_accs(all_accs):\n",
    "    N=np.shape(all_accs)[0]\n",
    "    all_means=np.mean(all_accs,axis=0)*100\n",
    "    all_maxs=np.percentile(all_accs, 90, axis=0)*100\n",
    "    all_stds=np.std(all_accs,axis=0)*100/np.sqrt(N)\n",
    "    train_mean=all_means[0];valid_mean=all_means[1];test_mean=all_means[2];\n",
    "    train_std=all_stds[0];valid_std=all_stds[1];test_std=all_stds[2];\n",
    "    test_max=all_maxs[2];\n",
    "    print(\"Train Acc \" + '{0:.2f}'.format(train_mean) + \" +- \" + '{0:.2f}'.format(train_std) +\n",
    "         \" Valid Acc \" + '{0:.2f}'.format(valid_mean) + \" +- \" + '{0:.2f}'.format(valid_std)  +\n",
    "         \" Test Acc \" + '{0:.2f}'.format(test_mean) + \" +- \" + '{0:.2f}'.format(test_std)  +\n",
    "         \" N = \" + str(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c728e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accs_noBrow,all_accs_Brow=get_accs_to_compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebe9d7",
   "metadata": {},
   "source": [
    "### Estimator uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6470595a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracies of the model without brownian augmentation:\n",
      "Train Acc 99.14 +- 0.02 Valid Acc 96.54 +- 0.02 Test Acc 93.04 +- 0.11 N = 277\n",
      "Checking accuracies of the model with brownian augmentation:\n",
      "Train Acc 98.68 +- 0.01 Valid Acc 96.58 +- 0.02 Test Acc 93.43 +- 0.10 N = 349\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking accuracies of the model without brownian augmentation:\")\n",
    "check_accs(all_accs_noBrow)\n",
    "print(\"Checking accuracies of the model with brownian augmentation:\")\n",
    "check_accs(all_accs_Brow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89f4e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=all_accs_Brow[:len(all_accs_noBrow),2]-all_accs_noBrow[:,2]; #Difference statistic (keeps less simulations, since there were more with the brownian one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "277530fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that the mean is higher than zero is approximately 0.98748%\n"
     ]
    }
   ],
   "source": [
    "m=np.mean(diff); #Mean of mean estimator\n",
    "sigma=np.std(diff)/np.sqrt(len(diff)); #Std of mean estimator\n",
    "prob_mu_hat_neg= stats.norm.cdf((0-m) / sigma);\n",
    "p_mu_hat_pos=1-prob_mu_hat_neg;\n",
    "print(\"The probability that the mean is higher than zero is approximately \" + '{0:.5f}'.format(p_mu_hat_pos) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664adc6e",
   "metadata": {},
   "source": [
    "### p-value test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1c30058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obtained p-value is: 1.77%. This value is significant to reject the null hypothesis and validate that the brownian augmentation has a better test accuracy!\n"
     ]
    }
   ],
   "source": [
    "mu_t=0.5;std_t=0.5;\n",
    "T_i=all_accs_Brow[:len(all_accs_noBrow),2]>all_accs_noBrow[:,2];\n",
    "N=len(T_i);\n",
    "avg_test=np.sum(T_i)/len(T_i)\n",
    "std_final= std_t/np.sqrt(N);\n",
    "z_score=(avg_test-mu_t)/std_final;\n",
    "p_value=1-stats.norm.cdf(z_score); #P(u>\\hat) |\\mu_T,\\sigma_T) Given the null hypothesis, what was the probability of the obtained results or worse!\n",
    "print(\"The obtained p-value is: \" + \"{:.2f}\".format(p_value*100) + \"%. This value is significant to reject the null hypothesis and validate that the brownian augmentation has a better test accuracy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49931779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020436263392851657\n"
     ]
    }
   ],
   "source": [
    "from math import comb\n",
    "mu_t=0.5;std_t=0.5;\n",
    "T_i=all_accs_Brow[:len(all_accs_noBrow),2]>all_accs_noBrow[:,2];\n",
    "N=len(T_i);\n",
    "s_e=sum(T_i);\n",
    "\n",
    "prob_H0=0\n",
    "for i in range(s_e,N):\n",
    "    prob_H0=prob_H0+comb(N,i)* 0.5**N;\n",
    "print(prob_H0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07e8ebc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5631768953068592"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_e/N"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
